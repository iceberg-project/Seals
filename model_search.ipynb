{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model search\n",
    "\n",
    "## Getting started\n",
    "\n",
    "This script will go through assembling the main components of a complete pipeline for counting seals in high-resolution satellite imagery. \n",
    "\n",
    "<img src=\"jupyter_notebook_images/pipeline.png\">\n",
    "** *environmental covariates not currently incorporated **\n",
    "\n",
    "If you followed the *training_set_generation* jupyter notebook (also present in this repo), you should have training sets generated and hyperparameter sets to try out, and be ready to search for a best performing model setup. Models will be evaluated at the three levels of the detection pipeline: **1)** their ability to identify scenes with seals, **2)** retrieve seal haul outs **3)** and count individual seals. Before training and validating model/hyperparameter combinations, we need to load the required python modules. Running this script will also display a list of training classes. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['crabeater', 'crack', 'emperor', 'glacier', 'ice-sheet', 'marching-emperor', 'open-water', 'other', 'pack-ice', 'rock', 'weddell']\n"
     ]
    }
   ],
   "source": [
    "# import required packages\n",
    "import os\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from functools import reduce\n",
    "from utils.model_library import * \n",
    "\n",
    "%matplotlib inline\n",
    "mpl.rcParams['figure.dpi']= 400\n",
    "\n",
    "\n",
    "# display class names\n",
    "class_names = sorted([subdir for subdir in os.listdir('./training_sets/training_set_vanilla/training')])\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training images (Optional)\n",
    "\n",
    "To get a better sense for what the training set is like, the next cell will display a few random images from the training classes. Displayed images are extracted from a pool of ~70000 training images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# store images\n",
    "images = []\n",
    "\n",
    "# loop over labels\n",
    "for label in class_names:\n",
    "    for path, _, files in os.walk('./training_sets/training_set_vanilla/training/{}'.format(label)):\n",
    "        files = np.random.choice(files, 5)\n",
    "        for filename in files:\n",
    "            images.append(np.asarray(Image.open(os.path.join(path, filename))))\n",
    "\n",
    "images = np.array(images)\n",
    "\n",
    "# display images \n",
    "ncols=len(class_names)\n",
    "nindex, height, width, intensity = images.shape\n",
    "nrows = nindex//ncols\n",
    "assert nindex == nrows*ncols\n",
    "result = (images.reshape(nrows, ncols, height, width, intensity)\n",
    "          .swapaxes(1,2)\n",
    "          .reshape(height*nrows, width*ncols, intensity))\n",
    "\n",
    "plt.imshow(result)\n",
    "cur_axes = plt.gca()\n",
    "cur_axes.axes.get_xaxis().set_visible(False)\n",
    "cur_axes.axes.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - haulout detector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to find a best performing model is to train different model setups using our training set. To keep track of which combinations we have tried and the specifics of each model setup, we will create a pandas DataFrame with model definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate model combinations\n",
    "combinations_haul = {'model_architecture': ['Resnet18'] * 4 + ['NasnetA'] * 4,\n",
    "                     'training_dir': ['training_set_vanilla', 'training_set_multiscale_A'] * 4,\n",
    "                     'hyperparameter_set': ['A'] * 4 + ['B'] * 4,\n",
    "                     'cv_weights': ['NO', 'NO', 'A', 'A'] * 2,\n",
    "                     'output_name': ['model{}'.format(i) for i in range(1,9)]}\n",
    "\n",
    "combinations_haul = pd.DataFrame(combinations_haul)\n",
    "\n",
    "# create folders for resulting files\n",
    "for mdl in combinations_haul['output_name']:\n",
    "    if not os.path.exists(\"./saved_models/haulout/{}\".format(mdl)):\n",
    "        os.makedirs(\"./saved_models/haulout/{}\".format(mdl)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then provide model combinations created above as arguments to the training script, *train_sealnet.py*. A list of required arguments can be displayed by running the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run train_sealnet.py -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# iterate over combinations\n",
    "for row in combinations_haul.iterrows():\n",
    "    t_dir, arch, hyp_st, cv_wgt, out = row[1]['training_dir'], row[1]['model_architecture'], row[1]['hyperparameter_set'], row[1]['cv_weights'], row[1]['output_name']\n",
    "    # check if model is already trained\n",
    "    if \"{}.tar\".format(out) in os.listdir('./saved_models/haulout/{}/'.format(out)): \n",
    "        print('{} was already trained'.format(out))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    !echo training $out\n",
    "    print()\n",
    "    \n",
    "    # run training\n",
    "    !python train_sealnet.py --training_dir=$t_dir --model_architecture=$arch --hyperparameter_set=$hyp_st --cv_weights=$cv_wgt --output_name=$out\n",
    "    \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training - single seal detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to training a model at the haulout level, we start by training a number of model combinations. To keep track of which combinations we have tried and the specifics of each model setup, we will create a pandas DataFrame with model definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate model combinations\n",
    "combinations_single = {'model_architecture': ['WideResnetA'] * 4,\n",
    "                       'training_dir': ['training_set_vanilla', 'training_set_multiscale_A'] * 2,\n",
    "                       'hyperparameter_set': ['C'] * 4,\n",
    "                       'cv_weights': ['NO', 'NO', 'A', 'A'],\n",
    "                       'output_name': ['model{}'.format(i) for i in range(1,5)]}\n",
    "\n",
    "combinations_single = pd.DataFrame(combinations_single)\n",
    "\n",
    "# create folders for resulting files\n",
    "for mdl in combinations_single['output_name']:\n",
    "    if not os.path.exists(\"./saved_models/single_seal/{}\".format(mdl)):\n",
    "        os.makedirs(\"./saved_models/single_seal/{}\".format(mdl)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the haulout models, we can provide model combinations created above as arguments to the training script, *train_sealnet.py*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "training model1\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "training Loss: 0.0616 Acc: 0.5316\n",
      "validation Loss: 0.3756 Acc: 0.6643\n",
      "training time: 0.0h 1m 23s\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "training Loss: 0.0499 Acc: 0.6131\n",
      "validation Loss: 0.3693 Acc: 0.6852\n",
      "training time: 0.0h 2m 46s\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "training Loss: 0.0463 Acc: 0.6395\n",
      "validation Loss: 0.3615 Acc: 0.6668\n",
      "training time: 0.0h 4m 9s\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "training Loss: 0.0448 Acc: 0.6495\n",
      "validation Loss: 0.3048 Acc: 0.7343\n",
      "training time: 0.0h 5m 33s\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "training Loss: 0.0433 Acc: 0.6628\n",
      "validation Loss: 0.3437 Acc: 0.6872\n",
      "training time: 0.0h 6m 57s\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "training Loss: 0.0416 Acc: 0.6740\n",
      "validation Loss: 0.3373 Acc: 0.6710\n",
      "training time: 0.0h 8m 20s\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "training Loss: 0.0411 Acc: 0.6803\n",
      "validation Loss: 0.3202 Acc: 0.6830\n",
      "training time: 0.0h 9m 43s\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "training Loss: 0.0401 Acc: 0.6873\n",
      "validation Loss: 0.3305 Acc: 0.6888\n",
      "training time: 0.0h 11m 8s\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "training Loss: 0.0396 Acc: 0.6908\n",
      "validation Loss: 0.3059 Acc: 0.7019\n",
      "training time: 0.0h 12m 32s\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "training Loss: 0.0394 Acc: 0.6928\n",
      "validation Loss: 0.2970 Acc: 0.7196\n",
      "training time: 0.0h 13m 55s\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "training Loss: 0.0387 Acc: 0.6988\n",
      "validation Loss: 0.2890 Acc: 0.7172\n",
      "training time: 0.0h 15m 19s\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "training Loss: 0.0379 Acc: 0.7037\n",
      "validation Loss: 0.2856 Acc: 0.7356\n",
      "training time: 0.0h 16m 42s\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "training Loss: 0.0375 Acc: 0.7090\n",
      "validation Loss: 0.2779 Acc: 0.7460\n",
      "training time: 0.0h 18m 5s\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "training Loss: 0.0370 Acc: 0.7109\n",
      "validation Loss: 0.2546 Acc: 0.7822\n",
      "training time: 0.0h 19m 28s\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "training Loss: 0.0365 Acc: 0.7128\n",
      "validation Loss: 0.2612 Acc: 0.7580\n",
      "training time: 0.0h 20m 51s\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "training Loss: 0.0365 Acc: 0.7145\n",
      "validation Loss: 0.2644 Acc: 0.7516\n",
      "training time: 0.0h 22m 15s\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "training Loss: 0.0362 Acc: 0.7165\n",
      "validation Loss: 0.2796 Acc: 0.7143\n",
      "training time: 0.0h 23m 37s\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "training Loss: 0.0357 Acc: 0.7211\n",
      "validation Loss: 0.2671 Acc: 0.7454\n",
      "training time: 0.0h 25m 2s\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "training Loss: 0.0354 Acc: 0.7226\n",
      "validation Loss: 0.2366 Acc: 0.7910\n",
      "training time: 0.0h 26m 25s\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "training Loss: 0.0353 Acc: 0.7242\n",
      "validation Loss: 0.2508 Acc: 0.7687\n",
      "training time: 0.0h 27m 48s\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "training Loss: 0.0348 Acc: 0.7280\n",
      "validation Loss: 0.2627 Acc: 0.7439\n",
      "training time: 0.0h 29m 12s\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "training Loss: 0.0347 Acc: 0.7282\n",
      "validation Loss: 0.2643 Acc: 0.7625\n",
      "training time: 0.0h 30m 36s\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "training Loss: 0.0341 Acc: 0.7348\n",
      "validation Loss: 0.2488 Acc: 0.7820\n",
      "training time: 0.0h 31m 59s\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "training Loss: 0.0339 Acc: 0.7357\n",
      "validation Loss: 0.2398 Acc: 0.7840\n",
      "training time: 0.0h 33m 22s\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "training Loss: 0.0337 Acc: 0.7343\n",
      "validation Loss: 0.2363 Acc: 0.7920\n",
      "training time: 0.0h 34m 45s\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "training Loss: 0.0332 Acc: 0.7404\n",
      "validation Loss: 0.2464 Acc: 0.7769\n",
      "training time: 0.0h 36m 11s\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "training Loss: 0.0335 Acc: 0.7383\n",
      "validation Loss: 0.2461 Acc: 0.7785\n",
      "training time: 0.0h 37m 34s\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "training Loss: 0.0334 Acc: 0.7390\n",
      "validation Loss: 0.2543 Acc: 0.7642\n",
      "training time: 0.0h 38m 57s\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "training Loss: 0.0330 Acc: 0.7421\n",
      "validation Loss: 0.2279 Acc: 0.8003\n",
      "training time: 0.0h 40m 20s\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "training Loss: 0.0333 Acc: 0.7404\n",
      "validation Loss: 0.2335 Acc: 0.7924\n",
      "training time: 0.0h 41m 44s\n",
      "\n",
      "Training complete in 0.0h 41m 44s\n",
      "\n",
      "training model2\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "training Loss: 0.0549 Acc: 0.5850\n",
      "validation Loss: 0.2673 Acc: 0.7877\n",
      "training time: 0.0h 5m 54s\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "training Loss: 0.0405 Acc: 0.7038\n",
      "validation Loss: 0.2601 Acc: 0.7887\n",
      "training time: 0.0h 8m 28s\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "training Loss: 0.0365 Acc: 0.7343\n",
      "validation Loss: 0.2398 Acc: 0.7997\n",
      "training time: 0.0h 10m 12s\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "training Loss: 0.0336 Acc: 0.7557\n",
      "validation Loss: 0.3002 Acc: 0.7088\n",
      "training time: 0.0h 11m 42s\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "training Loss: 0.0315 Acc: 0.7704\n",
      "validation Loss: 0.2407 Acc: 0.7820\n",
      "training time: 0.0h 13m 11s\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "training Loss: 0.0301 Acc: 0.7820\n",
      "validation Loss: 0.2055 Acc: 0.8238\n",
      "training time: 0.0h 14m 38s\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "training Loss: 0.0284 Acc: 0.7956\n",
      "validation Loss: 0.1924 Acc: 0.8379\n",
      "training time: 0.0h 16m 4s\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "training Loss: 0.0280 Acc: 0.7967\n",
      "validation Loss: 0.1879 Acc: 0.8343\n",
      "training time: 0.0h 17m 30s\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "training Loss: 0.0269 Acc: 0.8047\n",
      "validation Loss: 0.1891 Acc: 0.8335\n",
      "training time: 0.0h 18m 57s\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "training Loss: 0.0260 Acc: 0.8113\n",
      "validation Loss: 0.1800 Acc: 0.8375\n",
      "training time: 0.0h 20m 24s\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "training Loss: 0.0253 Acc: 0.8167\n",
      "validation Loss: 0.1658 Acc: 0.8612\n",
      "training time: 0.0h 21m 50s\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "training Loss: 0.0245 Acc: 0.8230\n",
      "validation Loss: 0.1613 Acc: 0.8651\n",
      "training time: 0.0h 23m 19s\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "training Loss: 0.0244 Acc: 0.8226\n",
      "validation Loss: 0.1388 Acc: 0.8821\n",
      "training time: 0.0h 24m 46s\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "training Loss: 0.0233 Acc: 0.8312\n",
      "validation Loss: 0.1574 Acc: 0.8664\n",
      "training time: 0.0h 26m 14s\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "training Loss: 0.0234 Acc: 0.8296\n",
      "validation Loss: 0.1698 Acc: 0.8513\n",
      "training time: 0.0h 27m 40s\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "training Loss: 0.0227 Acc: 0.8341\n",
      "validation Loss: 0.1567 Acc: 0.8686\n",
      "training time: 0.0h 29m 6s\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "training Loss: 0.0222 Acc: 0.8388\n",
      "validation Loss: 0.1461 Acc: 0.8731\n",
      "training time: 0.0h 30m 32s\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "training Loss: 0.0219 Acc: 0.8401\n",
      "validation Loss: 0.1577 Acc: 0.8673\n",
      "training time: 0.0h 32m 2s\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "training Loss: 0.0217 Acc: 0.8426\n",
      "validation Loss: 0.1411 Acc: 0.8794\n",
      "training time: 0.0h 33m 29s\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "training Loss: 0.0213 Acc: 0.8459\n",
      "validation Loss: 0.1488 Acc: 0.8721\n",
      "training time: 0.0h 34m 56s\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "training Loss: 0.0209 Acc: 0.8474\n",
      "validation Loss: 0.1451 Acc: 0.8820\n",
      "training time: 0.0h 36m 23s\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "training Loss: 0.0208 Acc: 0.8488\n",
      "validation Loss: 0.1413 Acc: 0.8819\n",
      "training time: 0.0h 37m 50s\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "training Loss: 0.0206 Acc: 0.8497\n",
      "validation Loss: 0.1355 Acc: 0.8881\n",
      "training time: 0.0h 39m 16s\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "training Loss: 0.0203 Acc: 0.8528\n",
      "validation Loss: 0.1551 Acc: 0.8673\n",
      "training time: 0.0h 40m 43s\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "training Loss: 0.0201 Acc: 0.8545\n",
      "validation Loss: 0.1391 Acc: 0.8843\n",
      "training time: 0.0h 42m 11s\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "training Loss: 0.0196 Acc: 0.8577\n",
      "validation Loss: 0.1381 Acc: 0.8856\n",
      "training time: 0.0h 43m 38s\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "training Loss: 0.0193 Acc: 0.8606\n",
      "validation Loss: 0.1407 Acc: 0.8807\n",
      "training time: 0.0h 45m 4s\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "training Loss: 0.0196 Acc: 0.8572\n",
      "validation Loss: 0.1448 Acc: 0.8783\n",
      "training time: 0.0h 46m 31s\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "training Loss: 0.0192 Acc: 0.8594\n",
      "validation Loss: 0.1345 Acc: 0.8899\n",
      "training time: 0.0h 47m 57s\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "training Loss: 0.0188 Acc: 0.8610\n",
      "validation Loss: 0.1240 Acc: 0.8956\n",
      "training time: 0.0h 49m 25s\n",
      "\n",
      "Training complete in 0.0h 49m 25s\n",
      "\n",
      "training model3\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "training Loss: 0.0490 Acc: 0.4917\n",
      "validation Loss: 0.5790 Acc: 0.5123\n",
      "training time: 0.0h 4m 40s\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "training Loss: 0.0390 Acc: 0.5835\n",
      "validation Loss: 0.3880 Acc: 0.6726\n",
      "training time: 0.0h 6m 42s\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "training Loss: 0.0360 Acc: 0.6140\n",
      "validation Loss: 0.3715 Acc: 0.6640\n",
      "training time: 0.0h 8m 11s\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "training Loss: 0.0340 Acc: 0.6322\n",
      "validation Loss: 0.4376 Acc: 0.5242\n",
      "training time: 0.0h 9m 36s\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "training Loss: 0.0333 Acc: 0.6388\n",
      "validation Loss: 0.3456 Acc: 0.6930\n",
      "training time: 0.0h 10m 59s\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "training Loss: 0.0320 Acc: 0.6502\n",
      "validation Loss: 0.3677 Acc: 0.6594\n",
      "training time: 0.0h 12m 24s\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "training Loss: 0.0317 Acc: 0.6531\n",
      "validation Loss: 0.3228 Acc: 0.7163\n",
      "training time: 0.0h 13m 48s\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Loss: 0.0308 Acc: 0.6618\n",
      "validation Loss: 0.3233 Acc: 0.7151\n",
      "training time: 0.0h 15m 14s\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "training Loss: 0.0301 Acc: 0.6694\n",
      "validation Loss: 0.3263 Acc: 0.7263\n",
      "training time: 0.0h 16m 37s\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "training Loss: 0.0294 Acc: 0.6741\n",
      "validation Loss: 0.3228 Acc: 0.7014\n",
      "training time: 0.0h 18m 3s\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "training Loss: 0.0291 Acc: 0.6782\n",
      "validation Loss: 0.2781 Acc: 0.7544\n",
      "training time: 0.0h 19m 28s\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "training Loss: 0.0288 Acc: 0.6818\n",
      "validation Loss: 0.2853 Acc: 0.7460\n",
      "training time: 0.0h 20m 52s\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "training Loss: 0.0278 Acc: 0.6896\n",
      "validation Loss: 0.2957 Acc: 0.7442\n",
      "training time: 0.0h 22m 16s\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "training Loss: 0.0277 Acc: 0.6911\n",
      "validation Loss: 0.3169 Acc: 0.6914\n",
      "training time: 0.0h 23m 39s\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "training Loss: 0.0273 Acc: 0.6934\n",
      "validation Loss: 0.2971 Acc: 0.7174\n",
      "training time: 0.0h 25m 3s\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "training Loss: 0.0274 Acc: 0.6947\n",
      "validation Loss: 0.2940 Acc: 0.7236\n",
      "training time: 0.0h 26m 28s\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "training Loss: 0.0272 Acc: 0.6976\n",
      "validation Loss: 0.2639 Acc: 0.7719\n",
      "training time: 0.0h 27m 52s\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "training Loss: 0.0266 Acc: 0.7042\n",
      "validation Loss: 0.2673 Acc: 0.7698\n",
      "training time: 0.0h 29m 14s\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "training Loss: 0.0263 Acc: 0.7043\n",
      "validation Loss: 0.2758 Acc: 0.7687\n",
      "training time: 0.0h 30m 40s\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "training Loss: 0.0263 Acc: 0.7060\n",
      "validation Loss: 0.2793 Acc: 0.7493\n",
      "training time: 0.0h 32m 5s\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "training Loss: 0.0258 Acc: 0.7109\n",
      "validation Loss: 0.2659 Acc: 0.7575\n",
      "training time: 0.0h 33m 28s\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "training Loss: 0.0255 Acc: 0.7125\n",
      "validation Loss: 0.2663 Acc: 0.7553\n",
      "training time: 0.0h 34m 51s\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "training Loss: 0.0254 Acc: 0.7143\n",
      "validation Loss: 0.2641 Acc: 0.7657\n",
      "training time: 0.0h 36m 15s\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "training Loss: 0.0250 Acc: 0.7167\n",
      "validation Loss: 0.2631 Acc: 0.7625\n",
      "training time: 0.0h 37m 39s\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "training Loss: 0.0249 Acc: 0.7191\n",
      "validation Loss: 0.2638 Acc: 0.7631\n",
      "training time: 0.0h 39m 3s\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "training Loss: 0.0245 Acc: 0.7206\n",
      "validation Loss: 0.2603 Acc: 0.7723\n",
      "training time: 0.0h 40m 26s\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "training Loss: 0.0245 Acc: 0.7212\n",
      "validation Loss: 0.2481 Acc: 0.7781\n",
      "training time: 0.0h 41m 51s\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "training Loss: 0.0243 Acc: 0.7227\n",
      "validation Loss: 0.2491 Acc: 0.7735\n",
      "training time: 0.0h 43m 14s\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "training Loss: 0.0243 Acc: 0.7251\n",
      "validation Loss: 0.2531 Acc: 0.7751\n",
      "training time: 0.0h 44m 36s\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "training Loss: 0.0243 Acc: 0.7255\n",
      "validation Loss: 0.2556 Acc: 0.7622\n",
      "training time: 0.0h 45m 59s\n",
      "\n",
      "Training complete in 0.0h 45m 59s\n",
      "\n",
      "training model4\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "training Loss: 0.0436 Acc: 0.5411\n",
      "validation Loss: 0.3316 Acc: 0.7363\n",
      "training time: 0.0h 5m 8s\n",
      "\n",
      "Epoch 2/30\n",
      "----------\n",
      "training Loss: 0.0323 Acc: 0.6583\n",
      "validation Loss: 0.2995 Acc: 0.7502\n",
      "training time: 0.0h 7m 30s\n",
      "\n",
      "Epoch 3/30\n",
      "----------\n",
      "training Loss: 0.0285 Acc: 0.6974\n",
      "validation Loss: 0.2450 Acc: 0.7949\n",
      "training time: 0.0h 9m 4s\n",
      "\n",
      "Epoch 4/30\n",
      "----------\n",
      "training Loss: 0.0263 Acc: 0.7217\n",
      "validation Loss: 0.2547 Acc: 0.7954\n",
      "training time: 0.0h 10m 31s\n",
      "\n",
      "Epoch 5/30\n",
      "----------\n",
      "training Loss: 0.0251 Acc: 0.7343\n",
      "validation Loss: 0.2845 Acc: 0.7678\n",
      "training time: 0.0h 11m 57s\n",
      "\n",
      "Epoch 6/30\n",
      "----------\n",
      "training Loss: 0.0234 Acc: 0.7516\n",
      "validation Loss: 0.2353 Acc: 0.7975\n",
      "training time: 0.0h 13m 23s\n",
      "\n",
      "Epoch 7/30\n",
      "----------\n",
      "training Loss: 0.0231 Acc: 0.7581\n",
      "validation Loss: 0.2154 Acc: 0.8241\n",
      "training time: 0.0h 14m 49s\n",
      "\n",
      "Epoch 8/30\n",
      "----------\n",
      "training Loss: 0.0218 Acc: 0.7666\n",
      "validation Loss: 0.1967 Acc: 0.8337\n",
      "training time: 0.0h 16m 15s\n",
      "\n",
      "Epoch 9/30\n",
      "----------\n",
      "training Loss: 0.0216 Acc: 0.7724\n",
      "validation Loss: 0.2101 Acc: 0.8150\n",
      "training time: 0.0h 17m 42s\n",
      "\n",
      "Epoch 10/30\n",
      "----------\n",
      "training Loss: 0.0206 Acc: 0.7810\n",
      "validation Loss: 0.1664 Acc: 0.8621\n",
      "training time: 0.0h 19m 8s\n",
      "\n",
      "Epoch 11/30\n",
      "----------\n",
      "training Loss: 0.0199 Acc: 0.7870\n",
      "validation Loss: 0.1867 Acc: 0.8478\n",
      "training time: 0.0h 20m 35s\n",
      "\n",
      "Epoch 12/30\n",
      "----------\n",
      "training Loss: 0.0195 Acc: 0.7921\n",
      "validation Loss: 0.1795 Acc: 0.8465\n",
      "training time: 0.0h 22m 2s\n",
      "\n",
      "Epoch 13/30\n",
      "----------\n",
      "training Loss: 0.0193 Acc: 0.7957\n",
      "validation Loss: 0.1829 Acc: 0.8478\n",
      "training time: 0.0h 23m 29s\n",
      "\n",
      "Epoch 14/30\n",
      "----------\n",
      "training Loss: 0.0189 Acc: 0.8000\n",
      "validation Loss: 0.1870 Acc: 0.8362\n",
      "training time: 0.0h 24m 55s\n",
      "\n",
      "Epoch 15/30\n",
      "----------\n",
      "training Loss: 0.0184 Acc: 0.8031\n",
      "validation Loss: 0.1737 Acc: 0.8510\n",
      "training time: 0.0h 26m 21s\n",
      "\n",
      "Epoch 16/30\n",
      "----------\n",
      "training Loss: 0.0178 Acc: 0.8091\n",
      "validation Loss: 0.1695 Acc: 0.8550\n",
      "training time: 0.0h 27m 47s\n",
      "\n",
      "Epoch 17/30\n",
      "----------\n",
      "training Loss: 0.0174 Acc: 0.8125\n",
      "validation Loss: 0.1706 Acc: 0.8566\n",
      "training time: 0.0h 29m 12s\n",
      "\n",
      "Epoch 18/30\n",
      "----------\n",
      "training Loss: 0.0173 Acc: 0.8135\n",
      "validation Loss: 0.1828 Acc: 0.8483\n",
      "training time: 0.0h 30m 37s\n",
      "\n",
      "Epoch 19/30\n",
      "----------\n",
      "training Loss: 0.0168 Acc: 0.8162\n",
      "validation Loss: 0.1614 Acc: 0.8649\n",
      "training time: 0.0h 32m 4s\n",
      "\n",
      "Epoch 20/30\n",
      "----------\n",
      "training Loss: 0.0170 Acc: 0.8169\n",
      "validation Loss: 0.1600 Acc: 0.8629\n",
      "training time: 0.0h 33m 31s\n",
      "\n",
      "Epoch 21/30\n",
      "----------\n",
      "training Loss: 0.0167 Acc: 0.8210\n",
      "validation Loss: 0.1513 Acc: 0.8695\n",
      "training time: 0.0h 34m 56s\n",
      "\n",
      "Epoch 22/30\n",
      "----------\n",
      "training Loss: 0.0166 Acc: 0.8190\n",
      "validation Loss: 0.1798 Acc: 0.8363\n",
      "training time: 0.0h 36m 24s\n",
      "\n",
      "Epoch 23/30\n",
      "----------\n",
      "training Loss: 0.0163 Acc: 0.8247\n",
      "validation Loss: 0.1495 Acc: 0.8710\n",
      "training time: 0.0h 37m 51s\n",
      "\n",
      "Epoch 24/30\n",
      "----------\n",
      "training Loss: 0.0159 Acc: 0.8258\n",
      "validation Loss: 0.1482 Acc: 0.8721\n",
      "training time: 0.0h 39m 16s\n",
      "\n",
      "Epoch 25/30\n",
      "----------\n",
      "training Loss: 0.0157 Acc: 0.8284\n",
      "validation Loss: 0.1514 Acc: 0.8712\n",
      "training time: 0.0h 40m 41s\n",
      "\n",
      "Epoch 26/30\n",
      "----------\n",
      "training Loss: 0.0154 Acc: 0.8321\n",
      "validation Loss: 0.1365 Acc: 0.8859\n",
      "training time: 0.0h 42m 7s\n",
      "\n",
      "Epoch 27/30\n",
      "----------\n",
      "training Loss: 0.0154 Acc: 0.8332\n",
      "validation Loss: 0.1487 Acc: 0.8705\n",
      "training time: 0.0h 43m 34s\n",
      "\n",
      "Epoch 28/30\n",
      "----------\n",
      "training Loss: 0.0154 Acc: 0.8339\n",
      "validation Loss: 0.1520 Acc: 0.8673\n",
      "training time: 0.0h 45m 2s\n",
      "\n",
      "Epoch 29/30\n",
      "----------\n",
      "training Loss: 0.0152 Acc: 0.8338\n",
      "validation Loss: 0.1598 Acc: 0.8615\n",
      "training time: 0.0h 46m 31s\n",
      "\n",
      "Epoch 30/30\n",
      "----------\n",
      "training Loss: 0.0149 Acc: 0.8369\n",
      "validation Loss: 0.1541 Acc: 0.8651\n",
      "training time: 0.0h 47m 57s\n",
      "\n",
      "Training complete in 0.0h 47m 57s\n",
      "\n",
      "training model5\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "Traceback (most recent call last):\n",
      "  File \"train_sealnet.py\", line 245, in <module>\n",
      "    main()\n",
      "  File \"train_sealnet.py\", line 241, in main\n",
      "    num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n",
      "  File \"train_sealnet.py\", line 158, in train_model\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/wide_resnet.py\", line 92, in forward\n",
      "    out = F.avg_pool2d(out, 7)\n",
      "RuntimeError: Given input size: (64x4x4). Calculated output size: (64x0x0). Output size is too small at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THCUNN/generic/SpatialAveragePooling.cu:63\n",
      "\n",
      "training model6\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "Traceback (most recent call last):\n",
      "  File \"train_sealnet.py\", line 245, in <module>\n",
      "    main()\n",
      "  File \"train_sealnet.py\", line 241, in main\n",
      "    num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n",
      "  File \"train_sealnet.py\", line 158, in train_model\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/wide_resnet.py\", line 92, in forward\n",
      "    out = F.avg_pool2d(out, 7)\n",
      "RuntimeError: Given input size: (64x4x4). Calculated output size: (64x0x0). Output size is too small at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THCUNN/generic/SpatialAveragePooling.cu:63\n",
      "\n",
      "training model7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "Traceback (most recent call last):\n",
      "  File \"train_sealnet.py\", line 245, in <module>\n",
      "    main()\n",
      "  File \"train_sealnet.py\", line 241, in main\n",
      "    num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n",
      "  File \"train_sealnet.py\", line 158, in train_model\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/wide_resnet.py\", line 92, in forward\n",
      "    out = F.avg_pool2d(out, 7)\n",
      "RuntimeError: Given input size: (64x4x4). Calculated output size: (64x0x0). Output size is too small at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THCUNN/generic/SpatialAveragePooling.cu:63\n",
      "\n",
      "training model8\n",
      "\n",
      "Epoch 1/30\n",
      "----------\n",
      "Traceback (most recent call last):\n",
      "  File \"train_sealnet.py\", line 245, in <module>\n",
      "    main()\n",
      "  File \"train_sealnet.py\", line 241, in main\n",
      "    num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n",
      "  File \"train_sealnet.py\", line 158, in train_model\n",
      "    outputs = model(inputs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\", line 491, in __call__\n",
      "    result = self.forward(*input, **kwargs)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/wide_resnet.py\", line 92, in forward\n",
      "    out = F.avg_pool2d(out, 7)\n",
      "RuntimeError: Given input size: (64x4x4). Calculated output size: (64x0x0). Output size is too small at /opt/conda/conda-bld/pytorch_1524590031827/work/aten/src/THCUNN/generic/SpatialAveragePooling.cu:63\n"
     ]
    }
   ],
   "source": [
    "# iterate over combinations\n",
    "for row in combinations_single.iterrows():\n",
    "    t_dir, arch, hyp_st, cv_wgt, out = row[1]['training_dir'], row[1]['model_architecture'], row[1]['hyperparameter_set'], row[1]['cv_weights'], row[1]['output_name']\n",
    "    # check if model is already trained\n",
    "    if \"{}.tar\".format(out) in os.listdir('./saved_models/single_seal/{}/'.format(out)): \n",
    "        print('{} was already trained'.format(out))\n",
    "        continue\n",
    "    \n",
    "    print()\n",
    "    !echo training $out\n",
    "    print()\n",
    "    \n",
    "    # run training\n",
    "    !python train_sealnet.py --training_dir=$t_dir --model_architecture=$arch --hyperparameter_set=$hyp_st --cv_weights=$cv_wgt --output_name=$out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - haulout level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now load the models we just trained to get measurements of precision and recall for all positive classes. For every model combination we trained, *validate_sealnet.py* will run a full validation round and write given label/correct label pairs to a .csv file. The resulting .csv file is then imported by an R script, *plot_confusion_matrix.R*, which saves a confusion matrix figure and a .csv spreadsheet with precision and recall for all classes of interest. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "validating model1\n",
      "\n",
      "Validation complete in 0.0h 0m 27s\n",
      "Validation Acc: 0.898638\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model2\n",
      "\n",
      "Validation complete in 0.0h 1m 1s\n",
      "Validation Acc: 0.863181\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model3\n",
      "\n",
      "Validation complete in 0.0h 0m 27s\n",
      "Validation Acc: 0.863309\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model4\n",
      "\n",
      "Validation complete in 0.0h 0m 27s\n",
      "Validation Acc: 0.731757\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model5\n",
      "\n",
      "Validation complete in 0.0h 4m 50s\n",
      "Validation Acc: 0.921891\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model6\n",
      "\n",
      "Validation complete in 0.0h 4m 43s\n",
      "Validation Acc: 0.917652\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model7\n",
      "\n",
      "Validation complete in 0.0h 4m 44s\n",
      "Validation Acc: 0.894142\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "\n",
      "validating model8\n",
      "\n",
      "Validation complete in 0.0h 4m 46s\n",
      "Validation Acc: 0.859841\n",
      "Loading required package: methods\n",
      "Warning: Ignoring unknown aesthetics: fill\n",
      "Loading required package: methods\n",
      "null device \n",
      "          1 \n"
     ]
    }
   ],
   "source": [
    "# DataFrame to combine all metrics \n",
    "comb_prec_recall = pd.DataFrame()\n",
    "\n",
    "# iterate over trained models\n",
    "for row in combinations_haul.iterrows():\n",
    "    \n",
    "    # read hyperparameters\n",
    "    t_dir, arch, hyp_st, out = row[1]['training_dir'], row[1]['model_architecture'], row[1]['hyperparameter_set'], row[1]['output_name']\n",
    "    \n",
    "    # check if model file is available\n",
    "    if \"{}.tar\".format(out) not in os.listdir('./saved_models/haulout/{}/'.format(out)): \n",
    "        print('{} has not been trained yet'.format(out))\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        print()\n",
    "        !echo validating $out\n",
    "        print()\n",
    "        \n",
    "        # run validation\n",
    "        !python validate_sealnet_haulout.py --training_dir=$t_dir --model_architecture=$arch --hyperparameter_set=$hyp_st --model_name=$out\n",
    "        \n",
    "        # extract performance\n",
    "        !Rscript plot_confusion_matrix.R $out\n",
    "        \n",
    "        # accumulate performance scores\n",
    "        comb_prec_recall = comb_prec_recall.append(pd.read_csv('./saved_models/haulout/{}/{}_haul_prec_recall.csv'.format(out, out)))\n",
    "    \n",
    "    \n",
    "# Write combined metrics to csv and plot combined metrics\n",
    "comb_prec_recall.to_csv('./saved_models/haulout/pooled_haul_prec_recall.csv')\n",
    "!Rscript plot_comparison.R './saved_models/haulout/pooled_haul_prec_recall.csv' './saved_models/haulout/haul_comparison_plot.png'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation - scene level\n",
    "\n",
    "The first step to validate models at the scene level is to tile out rasters to model input sizes. The following cell will search for all rasters in a dir, check if they are present in the scene_bank (see  *training_set_generation.ipynb*), store an affine matrix for that scene to go from the tile's index in the scene to projected coordinates and create tiles with the correct dimensions(including multi-scale models) for all model architectures in the 'combinations' DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load scene bank\n",
    "scene_bank = pd.read_csv('./training_sets/seals_scene_bank.csv')\n",
    "\n",
    "# point to raster dir\n",
    "raster_dir = '/home/bento/imagery'\n",
    "\n",
    "# create output folder\n",
    "%mkdir './tiled_images'\n",
    "\n",
    "# store data transforms\n",
    "affine_transforms = {}\n",
    "\n",
    "# loop through rasters creating tiled versions\n",
    "print('\\nTiling rasters:\\n')\n",
    "for path, _, files in os.walk(raster_dir):\n",
    "    # filter rasters to include only ones present in the scene bank\n",
    "    files = [file for file in files if file in pd.unique(scene_bank['scene'])]\n",
    "    for count, filename in enumerate(files):\n",
    "        filename_lower = filename.lower()\n",
    "        input_path = (os.path.join(path, filename))\n",
    "        # extract data transform to go from raster index to ESPG3031 coordinates\n",
    "        with rasterio.open(input_path) as src:\n",
    "            affine_transforms[filename] = [src.transform[1], src.transform[2], src.transform[0], src.transform[4], src.transform[5], src.transform[3]]\n",
    "        # loop over models\n",
    "        for row in combinations_haul.iterrows():\n",
    "            # get model input size\n",
    "            input_size = model_archs[row[1]['model_architecture']]\n",
    "            ts_scales = training_sets[row[1]['training_dir']]['scale_bands']\n",
    "            scales = [str(int(input_size * scale / ts_scales[0])) for scale in ts_scales]\n",
    "            scale_bands = reduce(lambda x,y: x + '_' + y, scales)\n",
    "            output_folder = './tiled_images/{}/{}'.format(input_path, scale_bands)\n",
    "            # create a tiled out image for that model if it doesn't exist\n",
    "            if os.path.exists(output_folder):\n",
    "                print('  {} was already split into tiles'.format(filename))\n",
    "                continue\n",
    "            !python tile_raster.py --scale_bands=$scale_bands  --input_image=$input_path --output_folder='./tiled_images'\n",
    "        print('\\nProcessed {} out of {} rasters'.format(count + 1, len(files)))\n",
    "\n",
    "# write data transforms to csv\n",
    "affine_transforms = pd.DataFrame(affine_transforms)\n",
    "affine_transforms.to_csv('affine_transforms.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With rasters tiled to the correct dimensions we can now run validation at the scene level. This procedure will work as follows: for each model, classify all images tiled in the previous step and save classification results to a pandas DataFrame. Results will be compared with the scene_bank to measure precision and recall at detecting which scenes contain positive entries (i.e. seals, penguins or even both, depending on the scene_bank being used). Locations marked as having seal haulouts will be used to detect individual seals and validate models at the seal level. To get validation results, run the following cell: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classifying tiles:\n",
      "\n",
      "  Tiles were already processed with model1\n",
      "  Tiles were already processed with model2\n",
      "  Tiles were already processed with model3\n",
      "  Tiles were already processed with model4\n",
      "  Tiles were already processed with model5\n",
      "  Tiles were already processed with model6\n",
      "  Tiles were already processed with model7\n",
      "  Tiles were already processed with model8\n",
      "\n",
      "Validating models:\n",
      "\n",
      "  Validated 1 out of 8 models\n",
      "  Validated 2 out of 8 models\n",
      "  Validated 3 out of 8 models\n",
      "  Validated 4 out of 8 models\n",
      "  Validated 5 out of 8 models\n",
      "  Validated 6 out of 8 models\n",
      "  Validated 7 out of 8 models\n",
      "  Validated 8 out of 8 models\n",
      "Loading required package: methods\n",
      "null device \n",
      "          1 \n"
     ]
    }
   ],
   "source": [
    "# loop through models classifying tiles\n",
    "print('\\nClassifying tiles:\\n')\n",
    "for row in combinations_haul.iterrows():\n",
    "    # store model classifications to get seal locations for seal level validation\n",
    "    val_scene_model = pd.DataFrame()\n",
    "    \n",
    "    # get model settings\n",
    "    arch = row[1]['model_architecture']\n",
    "    model_name = row[1]['output_name']\n",
    "    t_dir = row[1]['training_dir']\n",
    "    hyp_st = row[1]['hyperparameter_set']\n",
    "    \n",
    "    # check if model was already processed\n",
    "    if \"{}_scene_val.csv\".format(model_name) in os.listdir('./saved_models/haulout/{}/'.format(model_name)): \n",
    "        print('  Tiles were already processed with {}'.format(model_name))\n",
    "        continue\n",
    "    \n",
    "    # get scale bands\n",
    "    input_size = model_archs[arch]['input_size']\n",
    "    ts_scales = training_sets[t_dir]['scale_bands']\n",
    "    scales = [str(int(input_size * scale / ts_scales[0])) for scale in ts_scales]\n",
    "    scale_bands = reduce(lambda x,y: x + '_' + y, scales)\n",
    "    \n",
    "    # loop through tiled rasters\n",
    "    scenes = os.listdir('./tiled_images')\n",
    "    print('\\nClassifying tiled scenes with {}:'.format(model_name))\n",
    "    for count, scene in enumerate(scenes):\n",
    "        input_folder = './tiled_images/{}/{}'.format(scene, scale_bands)\n",
    "        %run predict_sealnet.py --training_dir=$t_dir --model_architecture=$arch --hyperparameter_set=$hyp_st --model_name=$model_name --data_dir=$input_folder --affine_transforms='affine_transforms.csv' --scene=$scene        \n",
    "        val_scene_model = val_scene_model.append(pd.read_csv('./saved_models/haulout/{}/{}_scene_val_tmp.csv'.format(model_name, model_name)), ignore_index=True)\n",
    "        print('\\n  Classified {} out of {} tiled scenes'.format(count + 1, len(scenes)))\n",
    "    \n",
    "    # save final classifications to csv and cleanup temporary stats\n",
    "    val_scene_model.to_csv('./saved_models/haulout/{}/{}_scene_val.csv'.format(model_name, model_name))\n",
    "    to_rm = './saved_models/haulout/{}/{}_scene_val_tmp.csv'.format(model_name, model_name)\n",
    "    !rm $to_rm\n",
    "\n",
    "# get precision and recall for classification at all scene banks\n",
    "comb_prec_rec = pd.DataFrame()\n",
    "\n",
    "print('\\nValidating models:\\n')\n",
    "# loop thorugh models again to get precision and recall\n",
    "for count, row in enumerate(combinations_haul.iterrows()):\n",
    "    # get model name\n",
    "    model_name = row[1]['output_name']\n",
    "    # get validation stats\n",
    "    %run validate_sealnet_scene.py --model_name=$model_name\n",
    "    comb_prec_rec = comb_prec_rec.append(pd.read_csv('./saved_models/haulout/{}/{}_scene_prec_recall.csv'.format(model_name, model_name)), ignore_index=True)\n",
    "    print('  Validated {} out of {} models'.format(count + 1, len(combinations_haul)))\n",
    "    \n",
    "# save combined precision recall to csv and plot it\n",
    "comb_prec_rec.to_csv('./saved_models/haulout/pooled_scene_prec_recall.csv', index=False)\n",
    "!Rscript plot_comparison.R './saved_models/haulout/pooled_scene_prec_recall.csv' './saved_models/haulout/scene_comparison_plot.png'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation -- single seal level\n",
    "\n",
    "With seal haulout locations determined, we can go ahead and try to count seals inside flagged seal haul out. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "----------\n",
      "training Loss: 2.1029\n",
      "validation Loss: 9.4041\n",
      "training time: 0.0h 37m 56s\n",
      "\n",
      "Epoch 2/5\n",
      "----------\n",
      "training Loss: 2.1184\n",
      "validation Loss: 9.4700\n",
      "training time: 1.0h 15m 25s\n",
      "\n",
      "Epoch 3/5\n",
      "----------\n",
      "training Loss: 2.0883\n",
      "validation Loss: 9.3499\n",
      "training time: 1.0h 53m 40s\n",
      "\n",
      "Epoch 4/5\n",
      "----------\n",
      "training Loss: 2.0652\n",
      "validation Loss: 9.5114\n",
      "training time: 2.0h 33m 18s\n",
      "\n",
      "Epoch 5/5\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-21:\n",
      "Process Process-23:\n",
      "Process Process-24:\n",
      "Process Process-22:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0;31m# start training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     model_ft = train_model(model, criterion, optimizer_ft, exp_lr_scheduler,\n\u001b[0;32m--> 241\u001b[0;31m                            num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, num_epochs)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_count.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_count.py\u001b[0m in \u001b[0;36mfeatures\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0mx_cell_11\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_11\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cell_10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cell_9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m         \u001b[0mx_reduction_cell_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction_cell_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_cell_11\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cell_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m         \u001b[0mx_cell_12\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell_12\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_reduction_cell_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_cell_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_count.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_prev)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0mx_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv_1x1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         \u001b[0mx_comb_iter_0_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomb_iter_0_left\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_right\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         \u001b[0mx_comb_iter_0_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomb_iter_0_right\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_left\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mx_comb_iter_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_comb_iter_0_left\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx_comb_iter_0_right\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_count.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseparable_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn_sep_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     47\u001b[0m         return F.batch_norm(\n\u001b[1;32m     48\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             self.training or not self.track_running_stats, self.momentum, self.eps)\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1192\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1193\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1194\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m     )\n\u001b[1;32m   1196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 110, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 167, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 149, in pil_loader\n",
      "    img = Image.open(f)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 2552, in open\n",
      "    prefix = fp.read(16)\n",
      "KeyboardInterrupt\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%run train_sealnet_count.py --training_dir=\"training_set_vanilla_count\" --model_architecture='NasnetACount' --hyperparameter_set='B' --cv_weights='NO' --output_name='count-ception'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n",
      "training Loss: 2.2607 Acc: 0.7001\n",
      "validation Loss: 14.8348 Acc: 0.6339\n",
      "training time: 1.0h 54m 43s\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n",
      "training Loss: 2.2659 Acc: 0.8595\n",
      "validation Loss: 18.3803 Acc: 0.5907\n",
      "training time: 3.0h 49m 29s\n",
      "\n",
      "Epoch 3/10\n",
      "----------\n",
      "training Loss: 2.1439 Acc: 0.8928\n",
      "validation Loss: 22.7197 Acc: 0.5870\n",
      "training time: 5.0h 44m 12s\n",
      "\n",
      "Epoch 4/10\n",
      "----------\n",
      "training Loss: 2.2004 Acc: 0.9147\n",
      "validation Loss: 22.0916 Acc: 0.5890\n",
      "training time: 7.0h 38m 49s\n",
      "\n",
      "Epoch 5/10\n",
      "----------\n",
      "training Loss: 2.2068 Acc: 0.9235\n",
      "validation Loss: 20.3537 Acc: 0.5889\n",
      "training time: 9.0h 33m 22s\n",
      "\n",
      "Epoch 6/10\n",
      "----------\n",
      "training Loss: 2.1304 Acc: 0.9363\n",
      "validation Loss: 22.2404 Acc: 0.5895\n",
      "training time: 11.0h 27m 54s\n",
      "\n",
      "Epoch 7/10\n",
      "----------\n",
      "training Loss: 2.1302 Acc: 0.9412\n",
      "validation Loss: 21.8812 Acc: 0.5890\n",
      "training time: 13.0h 22m 26s\n",
      "\n",
      "Epoch 8/10\n",
      "----------\n",
      "training Loss: 2.0879 Acc: 0.9478\n",
      "validation Loss: 25.9171 Acc: 0.5904\n",
      "training time: 15.0h 17m 2s\n",
      "\n",
      "Epoch 9/10\n",
      "----------\n",
      "training Loss: 2.1310 Acc: 0.9510\n",
      "validation Loss: 21.6361 Acc: 0.5889\n",
      "training time: 17.0h 14m 34s\n",
      "\n",
      "Epoch 10/10\n",
      "----------\n",
      "training Loss: 2.1503 Acc: 0.9538\n",
      "validation Loss: 22.4288 Acc: 0.5892\n",
      "training time: 19.0h 9m 48s\n",
      "\n",
      "Training complete in 19.0h 9m 48s\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'saved_models/single_seal/NasnetAe2e_V/NasnetAe2e_V.tar'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m     train_model(model, optimizer_ft, exp_lr_scheduler, criterion_class=criterion_class,\n\u001b[1;32m    261\u001b[0m                 \u001b[0mcriterion_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, criterion_class, num_epochs, criterion_count)\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_models/haulout/{}/{}.tar'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'saved_models/single_seal/{}/{}.tar'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0;34m>>\u001b[0m\u001b[0;34m>\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m     \"\"\"\n\u001b[0;32m--> 161\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_with_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_with_file_like\u001b[0;34m(f, mode, body)\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mnew_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'saved_models/single_seal/NasnetAe2e_V/NasnetAe2e_V.tar'"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-54:\n",
      "Process Process-51:\n",
      "Process Process-53:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-52:\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    260\u001b[0m     train_model(model, optimizer_ft, exp_lr_scheduler, criterion_class=criterion_class,\n\u001b[1;32m    261\u001b[0m                 \u001b[0mcriterion_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                 num_epochs=hyperparameters[args.hyperparameter_set]['epochs'])\n\u001b[0m\u001b[1;32m    263\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/train_sealnet_count_e2e.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, optimizer, scheduler, criterion_class, num_epochs, criterion_count)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                 \u001b[0;31m# forward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m                 \u001b[0mout_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mout_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mele\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mout_count\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_e2e.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    587\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/PycharmProjects/Seals_branches/Master/Seals/custom_architectures/nasnet_scalable_e2e.py\u001b[0m in \u001b[0;36mlogits\u001b[0;34m(self, features)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0mx1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_linear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mx2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/dropout.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(cls, ctx, input, p, train, inplace)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbernoulli_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 118, in __getitem__\n",
      "    sample = self.loader(path)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 167, in default_loader\n",
      "    return pil_loader(path)\n",
      "  File \"/home/bento/PycharmProjects/Seals_branches/Master/Seals/utils/data_loader_train_det.py\", line 150, in pil_loader\n",
      "    return img.convert('RGB')\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/PIL/Image.py\", line 877, in convert\n",
      "    self.load()\n",
      "  File \"/home/bento/anaconda3/lib/python3.6/site-packages/PIL/ImageFile.py\", line 236, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%run train_sealnet_count_e2e.py --training_dir=\"training_set_vanilla_count\" --model_architecture='NasnetAe2e' --hyperparameter_set='E' --cv_weights='NO' --output_name='NasnetAe2e_V'\n",
    "%run train_sealnet_count_e2e.py --training_dir=\"training_set_multiscale_A_count\" --model_architecture='NasnetAe2e' --hyperparameter_set='E' --cv_weights='NO' --output_name='NasnetAe2e_MS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'class_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-e9d06a47c3d3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir classified_images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./classified_images/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir -v $dir'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_names' is not defined"
     ]
    }
   ],
   "source": [
    "%mkdir classified_images\n",
    "for x in class_names:\n",
    "    dir = './classified_images/' + x\n",
    "    %mkdir -v $dir\n",
    "    \n",
    "%run predict_sealnet.py \"training_set_vanilla\" \"NasnetA\" \"model5\" \"./to_classify\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

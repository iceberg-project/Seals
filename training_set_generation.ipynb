{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SealNet Detection Pipeline -- Training set creation\n",
    "\n",
    "## Getting started\n",
    "\n",
    "This notebook will walk you through how we created the training set to train and validate instances of sealnet. From generating a vector database to extracting patches from rasters. To recreate the training set, you will need Qgis, Python 3.6, WV03 raster image catalog and a shapefile with a database for seal occurences (for a formatting reference see: *\"/shape_files/seal-points-train\"*).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents\n",
    "---\n",
    "* [Exporting points](#exp)\n",
    "* [Extracting patches](#extract)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting points <a name=\"exp\"></a>\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can extract patches from raster files, we need to export our database of seal points to a csv file. This operation can be performed with the MMQGIS plugin within Qgis using the 'export geometry' option. If you selected the correct shape file as the input layer, you will be prompted to save a .csv file. Keep the default name and move this .csv file to the root directory of this repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting patches<a name=\"extract\"></a>\n",
    "---\n",
    "\n",
    "Once the output from the geometry export is in the repository root, we are ready to extract patches from the raster files. Run the following cell to extract patches and create the training sets. This process will take around 20 minutes and requires at least 16GB of RAM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating training_set_vanilla:\n",
      "\n",
      "Checking input folder for invalid files:\n",
      "\n",
      "\n",
      "\n",
      "Creating dataset:\n",
      "\n",
      "\n",
      "  Processed 1 out of 52 rasters\n",
      "\n",
      "  Processed 2 out of 52 rasters\n",
      "\n",
      "  Processed 3 out of 52 rasters\n",
      "\n",
      "  Processed 4 out of 52 rasters\n",
      "\n",
      "  Processed 5 out of 52 rasters\n",
      "\n",
      "  Processed 6 out of 52 rasters\n",
      "\n",
      "  Processed 7 out of 52 rasters\n",
      "\n",
      "  Processed 8 out of 52 rasters\n",
      "\n",
      "  Processed 9 out of 52 rasters\n",
      "\n",
      "  Processed 10 out of 52 rasters\n",
      "\n",
      "  Processed 11 out of 52 rasters\n",
      "\n",
      "  Processed 12 out of 52 rasters\n",
      "\n",
      "  Processed 13 out of 52 rasters\n",
      "\n",
      "  Processed 14 out of 52 rasters\n",
      "\n",
      "  Processed 15 out of 52 rasters\n",
      "\n",
      "  Processed 16 out of 52 rasters\n",
      "\n",
      "  Processed 17 out of 52 rasters\n",
      "\n",
      "  Processed 18 out of 52 rasters\n",
      "\n",
      "  Processed 19 out of 52 rasters\n",
      "\n",
      "  Processed 20 out of 52 rasters\n",
      "\n",
      "  Processed 21 out of 52 rasters\n",
      "\n",
      "  Processed 22 out of 52 rasters\n",
      "\n",
      "  Processed 23 out of 52 rasters\n",
      "\n",
      "  Processed 24 out of 52 rasters\n",
      "\n",
      "  Processed 25 out of 52 rasters\n",
      "\n",
      "  Processed 26 out of 52 rasters\n",
      "\n",
      "  Processed 27 out of 52 rasters\n",
      "\n",
      "  Processed 28 out of 52 rasters\n",
      "\n",
      "  Processed 29 out of 52 rasters\n",
      "\n",
      "  Processed 30 out of 52 rasters\n",
      "\n",
      "  Processed 31 out of 52 rasters\n",
      "\n",
      "  Processed 32 out of 52 rasters\n",
      "\n",
      "  Processed 33 out of 52 rasters\n",
      "\n",
      "  Processed 34 out of 52 rasters\n",
      "\n",
      "  Processed 35 out of 52 rasters\n",
      "\n",
      "  Processed 36 out of 52 rasters\n",
      "\n",
      "  Processed 37 out of 52 rasters\n",
      "\n",
      "  Processed 38 out of 52 rasters\n",
      "\n",
      "  Processed 39 out of 52 rasters\n",
      "\n",
      "  Processed 40 out of 52 rasters\n",
      "\n",
      "  Processed 41 out of 52 rasters\n",
      "\n",
      "  Processed 42 out of 52 rasters\n",
      "\n",
      "  Processed 43 out of 52 rasters\n",
      "\n",
      "  Processed 44 out of 52 rasters\n",
      "\n",
      "  Processed 45 out of 52 rasters\n",
      "\n",
      "  Processed 46 out of 52 rasters\n",
      "\n",
      "  Processed 47 out of 52 rasters\n",
      "\n",
      "  Processed 48 out of 52 rasters\n",
      "\n",
      "  Processed 49 out of 52 rasters\n",
      "\n",
      "  Processed 50 out of 52 rasters\n",
      "\n",
      "  Processed 51 out of 52 rasters\n",
      "\n",
      "  Processed 52 out of 52 rasters\n",
      "\n",
      "\n",
      "86472 training images created in 14m 34s\n"
     ]
    }
   ],
   "source": [
    "# point to folder with raster images\n",
    "raster_dir = '/home/bento/GIS_projects/imagery/training_set_scenes'\n",
    "\n",
    "# training set vanilla\n",
    "\n",
    "# point to shapefile\n",
    "shape_file = 'temp-nodes.csv'\n",
    "# specify training labels, separate each class by an '_', classes need to correspond to ones in the shapefile\n",
    "labels = 'crabeater_crack_emperor_glacier_ice-sheet_marching-emperor_open-water_pack-ice_rock_shadow_weddell'\n",
    "# specify labels of classes used for detection\n",
    "det_classes = 'crabeater_weddell'\n",
    "\n",
    "%run create_trainingset.py --det_classes=$det_classes --rasters_dir=$raster_dir --scale_bands='450' --out_folder='training_set_vanilla' --labels=$labels --shape_file=$shape_file --rgb='0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
